import os
import numpy as np
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
from skimage.io import imread
from data.dataset import from_rgb_to_label, class_labels_dict, label_colours
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import csv

# è®¾ç½®å­—ä½“è·¯å¾„
font_path = "SIMSUN.TTC"
fm.fontManager.addfont(font_path)
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rcParams["font.sans-serif"] = [font_name]
plt.rcParams["axes.unicode_minus"] = False


class DatasetAnalyzer:
    """æ•°æ®é›†ç»Ÿè®¡åˆ†æå™¨"""

    def __init__(self, root_path):
        self.root_path = root_path
        self.class_names = list(class_labels_dict.keys())
        self.n_classes = len(self.class_names)
        self.results = {}

    def analyze_dataset(self, dataset_name):
        """åˆ†æå•ä¸ªæ•°æ®é›†"""
        dataset_path = os.path.join(self.root_path, dataset_name)
        if not os.path.exists(dataset_path):
            print(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return None

        print(f"\næ­£åœ¨åˆ†ææ•°æ®é›†: {dataset_name}")

        # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
        split_stats = {}
        total_pixel_counts = np.zeros(self.n_classes)
        total_pixels = 0
        class_appearance = defaultdict(set)  # æ¯ä¸ªç±»åˆ«å‡ºç°åœ¨å“ªäº›å›¾åƒä¸­
        class_areas = defaultdict(list)  # æ¯ä¸ªç±»åˆ«åœ¨å„å›¾åƒä¸­çš„é¢ç§¯

        # åˆ†ææ¯ä¸ªsplit
        for split in ["train", "val", "test"]:
            split_path = os.path.join(dataset_path, split)
            split_label_path = os.path.join(dataset_path, f"{split}_labels")

            if not os.path.exists(split_path) or not os.path.exists(split_label_path):
                print(f"è·³è¿‡ä¸å­˜åœ¨çš„split: {split}")
                split_stats[split] = {"count": 0}
                continue

            # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
            img_files = [
                f
                for f in os.listdir(split_path)
                if f.lower().endswith((".png", ".jpg", ".jpeg"))
            ]

            split_pixel_counts = np.zeros(self.n_classes)
            split_pixels = 0
            split_class_appearance = defaultdict(int)

            print(f"  å¤„ç† {split} split: {len(img_files)} å¼ å›¾åƒ")

            for i, img_file in enumerate(img_files):
                if i % 50 == 0:
                    print(f"    å¤„ç†è¿›åº¦: {i+1}/{len(img_files)}")

                # æ„å»ºæ ‡ç­¾æ–‡ä»¶è·¯å¾„
                base_name = os.path.splitext(img_file)[0]
                label_file = base_name + "_L.png"
                label_path = os.path.join(split_label_path, label_file)

                if not os.path.exists(label_path):
                    print(f"    è­¦å‘Š: æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨ {label_path}")
                    continue

                try:
                    # è¯»å–å¹¶è½¬æ¢æ ‡ç­¾
                    lbl_rgb = imread(label_path)
                    lbl = from_rgb_to_label(lbl_rgb)

                    # ç»Ÿè®¡åƒç´ æ•°
                    unique_labels, counts = np.unique(lbl, return_counts=True)
                    img_total_pixels = lbl.shape[0] * lbl.shape[1]

                    split_pixels += img_total_pixels
                    total_pixels += img_total_pixels

                    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«
                    for label_id, count in zip(unique_labels, counts):
                        if label_id < self.n_classes:
                            split_pixel_counts[label_id] += count
                            total_pixel_counts[label_id] += count

                            # è®°å½•ç±»åˆ«å‡ºç°
                            class_appearance[label_id].add(f"{split}_{img_file}")
                            split_class_appearance[label_id] += 1

                            # è®°å½•é¢ç§¯ï¼ˆåƒç´ æ•°ï¼‰
                            class_areas[label_id].append(count)

                except Exception as e:
                    print(f"    é”™è¯¯å¤„ç†æ–‡ä»¶ {label_path}: {e}")
                    continue

            # ä¿å­˜splitç»Ÿè®¡ä¿¡æ¯
            split_stats[split] = {
                "count": len(img_files),
                "total_pixels": split_pixels,
                "pixel_counts": split_pixel_counts.tolist(),
                "class_appearance": dict(split_class_appearance),
            }

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_images = sum(split_stats[s]["count"] for s in ["train", "val", "test"])

        # è®¡ç®—åƒç´ å æ¯”
        pixel_ratios = (
            total_pixel_counts / total_pixels
            if total_pixels > 0
            else np.zeros(self.n_classes)
        )

        # è®¡ç®—å‡ºç°é¢‘ç‡
        appearance_freq = {i: len(class_appearance[i]) for i in range(self.n_classes)}

        # è®¡ç®—æœ€å¤§æœ€å°é¢ç§¯
        area_stats = {}
        for class_id in range(self.n_classes):
            if class_areas[class_id]:
                area_stats[class_id] = {
                    "max_area": max(class_areas[class_id]),
                    "min_area": min(class_areas[class_id]),
                    "mean_area": np.mean(class_areas[class_id]),
                    "total_instances": len(class_areas[class_id]),
                }
            else:
                area_stats[class_id] = {
                    "max_area": 0,
                    "min_area": 0,
                    "mean_area": 0,
                    "total_instances": 0,
                }

        # æ•´åˆç»“æœ
        result = {
            "dataset_name": dataset_name,
            "total_images": total_images,
            "total_pixels": total_pixels,
            "n_classes": self.n_classes,
            "class_names": self.class_names,
            "split_distribution": {
                "train": split_stats.get("train", {}).get("count", 0),
                "val": split_stats.get("val", {}).get("count", 0),
                "test": split_stats.get("test", {}).get("count", 0),
            },
            "pixel_statistics": {
                "total_pixel_counts": total_pixel_counts.tolist(),
                "pixel_ratios": pixel_ratios.tolist(),
                "pixel_percentages": (pixel_ratios * 100).tolist(),
            },
            "appearance_frequency": appearance_freq,
            "area_statistics": area_stats,
            "split_details": split_stats,
        }

        return result

    def print_statistics(self, result):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        if result is None:
            return

        print(f"\n{'='*60}")
        print(f"æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š: {result['dataset_name']}")
        print(f"{'='*60}")

        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"æ€»å›¾åƒæ•°é‡: {result['total_images']}")
        print(f"ç±»åˆ«æ•°é‡: {result['n_classes']}")
        print(f"æ€»åƒç´ æ•°: {result['total_pixels']:,}")

        # æ•°æ®é›†åˆ†å¸ƒ
        print(f"\nğŸ“ æ•°æ®é›†åˆ†å¸ƒ:")
        total = result["total_images"]
        splits = result["split_distribution"]
        for split_name, count in splits.items():
            ratio = count / total * 100 if total > 0 else 0
            print(f"{split_name:>6}: {count:>6} å¼  ({ratio:>5.1f}%)")

        # åƒç´ å æ¯”ç»Ÿè®¡
        print(f"\nğŸ¨ å„ç±»åˆ«åƒç´ å æ¯”:")
        pixel_stats = result["pixel_statistics"]
        print(f"{'ç±»åˆ«':<15} {'åƒç´ æ•°':<12} {'å æ¯”':<10} {'ç™¾åˆ†æ¯”':<10}")
        print("-" * 50)
        for i, class_name in enumerate(result["class_names"]):
            pixel_count = int(pixel_stats["total_pixel_counts"][i])
            ratio = pixel_stats["pixel_ratios"][i]
            percentage = pixel_stats["pixel_percentages"][i]
            print(
                f"{class_name:<15} {pixel_count:<12,} {ratio:<10.6f} {percentage:<10.2f}%"
            )

        # å‡ºç°é¢‘ç‡
        print(f"\nğŸ“ˆ ç±»åˆ«å‡ºç°é¢‘ç‡:")
        print(f"{'ç±»åˆ«':<15} {'å‡ºç°å›¾åƒæ•°':<12} {'å‡ºç°ç‡':<10}")
        print("-" * 40)
        for i, class_name in enumerate(result["class_names"]):
            freq = result["appearance_frequency"][i]
            freq_ratio = freq / total * 100 if total > 0 else 0
            print(f"{class_name:<15} {freq:<12} {freq_ratio:<10.2f}%")

        # é¢ç§¯ç»Ÿè®¡
        print(f"\nğŸ“ ç±»åˆ«é¢ç§¯ç»Ÿè®¡:")
        print(
            f"{'ç±»åˆ«':<15} {'å®ä¾‹æ•°':<8} {'æœ€å°é¢ç§¯':<10} {'æœ€å¤§é¢ç§¯':<10} {'å¹³å‡é¢ç§¯':<10}"
        )
        print("-" * 65)
        for i, class_name in enumerate(result["class_names"]):
            area_stat = result["area_statistics"][i]
            instances = area_stat["total_instances"]
            min_area = area_stat["min_area"]
            max_area = area_stat["max_area"]
            mean_area = area_stat["mean_area"]
            print(
                f"{class_name:<15} {instances:<8} {min_area:<10} {max_area:<10} {mean_area:<10.1f}"
            )
    def save_to_csv(self, result, output_dir):
            """å°†ç»Ÿè®¡ç»“æœä¿å­˜ä¸ºCSVæ–‡ä»¶"""
            if result is None:
                print("æ²¡æœ‰ç»“æœå¯ä¿å­˜")
                return

            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ä¿å­˜åƒç´ ç»Ÿè®¡æ•°æ®
            pixel_stats_file = os.path.join(output_dir, f"{result['dataset_name']}_pixel_statistics.csv")
            with open(pixel_stats_file, mode="w", newline="", encoding="utf-8") as file:
                writer = csv.writer(file)
                writer.writerow(["ç±»åˆ«", "åƒç´ æ•°", "å æ¯”", "ç™¾åˆ†æ¯”"])
                for i, class_name in enumerate(result["class_names"]):
                    writer.writerow([
                        class_name,
                        int(result["pixel_statistics"]["total_pixel_counts"][i]),
                        result["pixel_statistics"]["pixel_ratios"][i],
                        result["pixel_statistics"]["pixel_percentages"][i],
                    ])

            # ä¿å­˜ç±»åˆ«é¢ç§¯ç»Ÿè®¡æ•°æ®
            area_stats_file = os.path.join(output_dir, f"{result['dataset_name']}_area_statistics.csv")
            with open(area_stats_file, mode="w", newline="", encoding="utf-8") as file:
                writer = csv.writer(file)
                writer.writerow(["ç±»åˆ«", "å®ä¾‹æ•°", "æœ€å°é¢ç§¯", "æœ€å¤§é¢ç§¯", "å¹³å‡é¢ç§¯"])
                for i, class_name in enumerate(result["class_names"]):
                    area_stat = result["area_statistics"][i]
                    writer.writerow([
                        class_name,
                        area_stat["total_instances"],
                        area_stat["min_area"],
                        area_stat["max_area"],
                        area_stat["mean_area"],
                    ])

            print(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜ä¸ºCSVæ–‡ä»¶: {output_dir}")
    def create_visualization(self, results, output_dir):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ä»datasetä¸­è·å–ç±»åˆ«é¢œè‰²ï¼Œè½¬æ¢ä¸ºmatplotlibæ ¼å¼
        def get_class_colors():
            colors = []
            for color_list in label_colours:
                # å–æ¯ä¸ªç±»åˆ«çš„ç¬¬ä¸€ä¸ªé¢œè‰²ï¼Œå¹¶è½¬æ¢ä¸º0-1èŒƒå›´
                rgb = [c / 255.0 for c in color_list[0]]
                colors.append(rgb)
            return colors

        class_colors = get_class_colors()

        for dataset_name, result in results.items():
            if result is None:
                continue

            # 1. æ•°æ®é›†åˆ’åˆ†æ‰‡å½¢å›¾
            plt.figure(figsize=(8, 8))
            splits = list(result["split_distribution"].keys())
            counts = list(result["split_distribution"].values())

            # è¿‡æ»¤æ‰æ•°é‡ä¸º0çš„split
            filtered_splits = []
            filtered_counts = []
            for split, count in zip(splits, counts):
                if count > 0:
                    filtered_splits.append(split)
                    filtered_counts.append(count)

            if filtered_counts:
                colors_split = ["#FF6B6B", "#4ECDC4", "#45B7D1"][: len(filtered_splits)]
                
                # è‡ªå®šä¹‰æ˜¾ç¤ºç™¾åˆ†æ¯”å’Œæ•°é‡
                def autopct_format(pct, all_vals):
                    absolute = int(round(pct / 100. * sum(all_vals)))
                    return f"{pct:.1f}%\n({absolute})"

                wedges, texts, autotexts = plt.pie(
                    filtered_counts,
                    labels=None,
                    autopct=lambda pct: autopct_format(pct, filtered_counts),  # è‡ªå®šä¹‰æ˜¾ç¤ºå†…å®¹
                    startangle=90,
                    colors=colors_split,
                )
                # è°ƒæ•´ç™¾åˆ†æ¯”å­—ä½“å¤§å°
                for autotext in autotexts:
                    autotext.set_fontsize(15)  # è®¾ç½®ç™¾åˆ†æ¯”å­—ä½“å¤§å°ä¸º 15ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
                plt.title(f"{dataset_name} - è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ†å¸ƒ", fontsize=15)
                plt.axis("equal")
                # è®¾ç½® å›¾æ³¨
                plt.legend(filtered_splits, loc="upper right", fontsize=15)
                plt.tight_layout()
                plt.savefig(
                    os.path.join(output_dir, f"{dataset_name}_split_distribution.png"),
                    dpi=300,
                    bbox_inches="tight",
                    pad_inches=0,
                )
            plt.close()

            # 2. åƒç´ åˆ†å¸ƒæŸ±çŠ¶å›¾ï¼ˆä½¿ç”¨ç±»åˆ«é¢œè‰²ï¼‰
            plt.figure(figsize=(15, 8))
            percentages = result["pixel_statistics"]["pixel_percentages"]
            class_names = result["class_names"]

            # åˆ›å»ºæŸ±çŠ¶å›¾
            x_pos = np.arange(len(class_names))
            bars = plt.bar(x_pos, percentages, color=class_colors[: len(class_names)])

            plt.title(f"{dataset_name} - å„ç±»åˆ«åƒç´ å æ¯”åˆ†å¸ƒ", fontsize=15)
            plt.xlabel("ç±»åˆ«", fontsize=15)
            plt.ylabel("åƒç´ å æ¯” (%)", fontsize=15)
            plt.xticks(x_pos, class_names, rotation=45, ha="right", fontsize=12)
            plt.yticks(fontsize=12)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, pct) in enumerate(zip(bars, percentages)):
                if pct > 0.1:  # åªä¸ºå æ¯”å¤§äº0.1%çš„ç±»åˆ«æ·»åŠ æ ‡ç­¾
                    plt.text(
                        bar.get_x() + bar.get_width() / 2,
                        bar.get_height() + 0.1,
                        f"{pct:.1f}%",
                        ha="center",
                        va="bottom",
                        fontsize=15,
                    )

            plt.tight_layout()
            plt.savefig(
                os.path.join(output_dir, f"{dataset_name}_pixel_distribution.png"),
                dpi=300,
                bbox_inches="tight",
                pad_inches=0,
            )
            plt.close()
        plt.figure(figsize=(12, 6))
        n_cols = 5  # æ¯è¡Œæ˜¾ç¤ºçš„è‰²å—æ•°é‡
        n_rows = (len(class_names) + n_cols - 1) // n_cols  # è®¡ç®—è¡Œæ•°
        cell_width = 2
        cell_height = 1

        fig, ax = plt.subplots(figsize=(n_cols * cell_width, n_rows * cell_height))
        ax.set_xlim(0, n_cols)
        ax.set_ylim(0, n_rows)
        ax.axis("off")

        for i, class_name in enumerate(class_names):
            row = i // n_cols
            col = i % n_cols
            color = class_colors[i]
            rect = plt.Rectangle(
                (col, n_rows - row - 1), 1, 1, color=color, transform=ax.transData
            )
            ax.add_patch(rect)
            ax.text(
                col + 0.5,
                n_rows - row - 0.5,
                class_name,
                color="white",
                ha="center",
                va="center",
                fontsize=15,
                weight="bold",
            )

        plt.tight_layout()
        plt.savefig(
            os.path.join(output_dir, f"{dataset_name}_class_color_blocks.png"),
            dpi=300,
            bbox_inches="tight",
            pad_inches=0,
        )
        plt.close()
        

        print(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")


def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®é›†æ ¹è·¯å¾„
    root_path = "CamVid"  # æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹

    # åˆ›å»ºåˆ†æå™¨
    analyzer = DatasetAnalyzer(root_path)

    # åˆ†æä¸¤ä¸ªæ•°æ®é›†
    datasets = ["sunny", "cloudy"]
    all_results = {}

    for dataset in datasets:
        result = analyzer.analyze_dataset(dataset)
        all_results[dataset] = result
        analyzer.print_statistics(result)
        csv_output_dir = os.path.join(os.path.dirname(__file__), "data/statistics")
        analyzer.save_to_csv(result, csv_output_dir)

    # åˆ›å»ºå¯è§†åŒ–
    output_dir = os.path.join(os.path.dirname(__file__), "data/visualization")
    analyzer.create_visualization(all_results, output_dir)

    # æ‰“å°æ±‡æ€»å¯¹æ¯”
    print(f"\n{'='*80}")
    print("æ•°æ®é›†å¯¹æ¯”æ±‡æ€»")
    print(f"{'='*80}")

    print(f"{'æŒ‡æ ‡':<20} {'Sunny':<15} {'Cloudy':<15}")
    print("-" * 50)

    for dataset in datasets:
        if all_results[dataset] is not None:
            result = all_results[dataset]
            print(f"æ€»å›¾åƒæ•°:{'':<12} {result['total_images']:<15}")
            print(f"è®­ç»ƒé›†:{'':<14} {result['split_distribution']['train']:<15}")
            print(f"éªŒè¯é›†:{'':<14} {result['split_distribution']['val']:<15}")
            print(f"æµ‹è¯•é›†:{'':<14} {result['split_distribution']['test']:<15}")
            print(f"æ€»åƒç´ æ•°:{'':<12} {result['total_pixels']:<15,}")
            print("-" * 50)


if __name__ == "__main__":
    main()
